// -*- c++ -*-

// code guard
#if !defined(pyre_cuda_memory_DevicePinned_icc)
#error this file contains implementation details for pyre::cuda::memory::DevicePinned
#else

// metamethods
// constructor
template <class T, bool isConst>
pyre::cuda::memory::DevicePinned<T, isConst>::DevicePinned(
    cell_count_type cells) : // the cuda {malloc} api is not RAII friendly, so we initialize with a
                             // {nullptr} and replace it with the actual allocation
    _data { nullptr },
    _cells { cells }
{
    // grab a spot
    pointer spot = nullptr;
    // compute the memory footprint
    auto footprint = cells * sizeof(value_type);
    // allocate memory
    auto status = cudaMalloc(&spot, footprint);
    // if something went wrong
    if (status != cudaSuccess) {
        // make a channel
        pyre::journal::error_t error("pyre.cuda");
        // complain
        error << "while allocating " << footprint
              << " bytes of device memory: " << pyre::journal::newline << cudaGetErrorName(status)
              << " (" << status << ")" << pyre::journal::endl(__HERE__);
        // and bail
        throw std::bad_alloc();
    }

    // all went well
    pyre::journal::debug_t channel("pyre.cuda.pinned_t");
    // so let me know
    channel << "allocated " << footprint << " bytes at " << (void *) spot
            << pyre::journal::endl(__HERE__);

    // if all went well, make a deleter for CUDA allocated memory
    auto destructor = [footprint](auto ptr) {
        // attempt to free the block of memory
        auto status = cudaFree(ptr);
        // if something went wrong
        if (status != cudaSuccess) {
            // make a channel
            pyre::journal::error_t error("pyre.cuda");
            // complain
            error << "while deallocating " << footprint
                  << " bytes of device memory: " << pyre::journal::newline
                  << cudaGetErrorName(status) << " (" << status << ")"
                  << pyre::journal::endl(__HERE__);
        }
        // all went well
        pyre::journal::debug_t channel("pyre.cuda.pinned_t");
        // so let me know
        channel << "deallocated " << footprint << " bytes starting at " << (void *) ptr
                << " on the device" << pyre::journal::endl(__HERE__);
        // all done
        return;
    };

    // replace the {nullptr} with the new block and register the deallocator
    _data.reset(spot, destructor);
}

template <class T, bool isConst>
pyre::cuda::memory::DevicePinned<T, isConst>::DevicePinned(
    handle_type handle, cell_count_type cells) :
    _data { handle },
    _cells { cells }
{}


// interface
// get the number of cells in the block
template <class T, bool isConst>
auto
pyre::cuda::memory::DevicePinned<T, isConst>::cells() const -> cell_count_type
{
    // easy
    return _cells;
}

// get the memory footprint of the block
template <class T, bool isConst>
auto
pyre::cuda::memory::DevicePinned<T, isConst>::bytes() const -> size_type
{
    // scale the number of cells by the cell size
    return cells() * sizeof(value_type);
}

// access to the data pointer
template <class T, bool isConst>
auto
pyre::cuda::memory::DevicePinned<T, isConst>::data() const -> pointer
{
    // return the raw data pointer
    return _data.get();
}

// get the shared pointer
template <class T, bool isConst>
auto
pyre::cuda::memory::DevicePinned<T, isConst>::handle() const -> handle_type
{
    // easy
    return _data;
}

// iterator support
template <class T, bool isConst>
auto
pyre::cuda::memory::DevicePinned<T, isConst>::begin() const -> pointer
{
    // the beginning of the block
    return data();
}

template <class T, bool isConst>
auto
pyre::cuda::memory::DevicePinned<T, isConst>::end() const -> pointer
{
    // one past the last cell in the block
    return data() + cells();
}

#endif

// end of file
